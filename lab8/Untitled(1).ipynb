{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbbfcf54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T10:50:53.210870900Z",
     "start_time": "2023-11-08T10:50:49.642605600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_public: (30000, 58)\n",
      "Shape of y_public: (30000,)\n",
      "epoch:  0  accuracy:  0.4674  loss:  0.696997344493866\n",
      "epoch:  1  accuracy:  0.4674  loss:  0.6964302062988281\n",
      "epoch:  2  accuracy:  0.4674  loss:  0.6958906054496765\n",
      "epoch:  3  accuracy:  0.4674  loss:  0.6953808665275574\n",
      "epoch:  4  accuracy:  0.4674  loss:  0.6949030160903931\n",
      "epoch:  5  accuracy:  0.4674  loss:  0.6944543123245239\n",
      "epoch:  6  accuracy:  0.4674  loss:  0.6940342783927917\n",
      "epoch:  7  accuracy:  0.46773333333333333  loss:  0.6936423182487488\n",
      "epoch:  8  accuracy:  0.4686  loss:  0.6932791471481323\n",
      "epoch:  9  accuracy:  0.5244  loss:  0.6929445266723633\n",
      "epoch:  10  accuracy:  0.5326  loss:  0.6926376223564148\n",
      "epoch:  11  accuracy:  0.5326  loss:  0.6923587322235107\n",
      "epoch:  12  accuracy:  0.5326  loss:  0.6921088695526123\n",
      "epoch:  13  accuracy:  0.5326  loss:  0.6918883919715881\n",
      "epoch:  14  accuracy:  0.5326  loss:  0.6916983127593994\n",
      "epoch:  15  accuracy:  0.5326  loss:  0.6915387511253357\n",
      "epoch:  16  accuracy:  0.5326  loss:  0.6914101839065552\n",
      "epoch:  17  accuracy:  0.5326  loss:  0.6913228034973145\n",
      "epoch:  18  accuracy:  0.5326  loss:  0.6912471652030945\n",
      "epoch:  19  accuracy:  0.5326  loss:  0.6911928653717041\n",
      "epoch:  20  accuracy:  0.5326  loss:  0.6911566257476807\n",
      "epoch:  21  accuracy:  0.5326  loss:  0.6911354064941406\n",
      "epoch:  22  accuracy:  0.5326  loss:  0.691127359867096\n",
      "epoch:  23  accuracy:  0.5326  loss:  0.6911265850067139\n",
      "epoch:  24  accuracy:  0.5326  loss:  0.6911316514015198\n",
      "epoch:  25  accuracy:  0.5326  loss:  0.6911396980285645\n",
      "epoch:  26  accuracy:  0.5326  loss:  0.691145658493042\n",
      "epoch:  27  accuracy:  0.5326  loss:  0.6911489367485046\n",
      "epoch:  28  accuracy:  0.5326  loss:  0.6911450624465942\n",
      "epoch:  29  accuracy:  0.5326  loss:  0.6911333203315735\n",
      "epoch:  30  accuracy:  0.5326  loss:  0.6911149621009827\n",
      "epoch:  31  accuracy:  0.5326  loss:  0.6910885572433472\n",
      "epoch:  32  accuracy:  0.5326  loss:  0.6910557150840759\n",
      "epoch:  33  accuracy:  0.5326  loss:  0.6910195350646973\n",
      "epoch:  34  accuracy:  0.5326  loss:  0.6909797191619873\n",
      "epoch:  35  accuracy:  0.5326  loss:  0.6909388899803162\n",
      "epoch:  36  accuracy:  0.5326  loss:  0.6908980011940002\n",
      "epoch:  37  accuracy:  0.5326  loss:  0.6908567547798157\n",
      "epoch:  38  accuracy:  0.5326  loss:  0.69081711769104\n",
      "epoch:  39  accuracy:  0.5326  loss:  0.690778911113739\n",
      "epoch:  40  accuracy:  0.5326  loss:  0.6907445192337036\n",
      "epoch:  41  accuracy:  0.5326  loss:  0.6907106637954712\n",
      "epoch:  42  accuracy:  0.5326  loss:  0.6906791925430298\n",
      "epoch:  43  accuracy:  0.5326  loss:  0.6906509399414062\n",
      "epoch:  44  accuracy:  0.5326  loss:  0.690624475479126\n",
      "epoch:  45  accuracy:  0.5326  loss:  0.69059818983078\n",
      "epoch:  46  accuracy:  0.5326  loss:  0.6905719041824341\n",
      "epoch:  47  accuracy:  0.5326  loss:  0.6905462145805359\n",
      "epoch:  48  accuracy:  0.5326  loss:  0.6905203461647034\n",
      "epoch:  49  accuracy:  0.5326  loss:  0.6904935240745544\n",
      "epoch:  50  accuracy:  0.5326  loss:  0.6904647350311279\n",
      "epoch:  51  accuracy:  0.5326  loss:  0.6904336214065552\n",
      "epoch:  52  accuracy:  0.5326  loss:  0.6904008984565735\n",
      "epoch:  53  accuracy:  0.5326  loss:  0.6903660297393799\n",
      "epoch:  54  accuracy:  0.5326  loss:  0.6903294920921326\n",
      "epoch:  55  accuracy:  0.5326  loss:  0.6902915835380554\n",
      "epoch:  56  accuracy:  0.5326  loss:  0.6902530193328857\n",
      "epoch:  57  accuracy:  0.5326  loss:  0.690215528011322\n",
      "epoch:  58  accuracy:  0.5326  loss:  0.6901811361312866\n",
      "epoch:  59  accuracy:  0.5326  loss:  0.6901477575302124\n",
      "epoch:  60  accuracy:  0.5326  loss:  0.690112292766571\n",
      "epoch:  61  accuracy:  0.5326  loss:  0.6900749802589417\n",
      "epoch:  62  accuracy:  0.5326  loss:  0.6900362968444824\n",
      "epoch:  63  accuracy:  0.5326  loss:  0.6899964809417725\n",
      "epoch:  64  accuracy:  0.5326  loss:  0.6899555921554565\n",
      "epoch:  65  accuracy:  0.5326  loss:  0.6899135708808899\n",
      "epoch:  66  accuracy:  0.5326  loss:  0.6898705363273621\n",
      "epoch:  67  accuracy:  0.5326  loss:  0.6898271441459656\n",
      "epoch:  68  accuracy:  0.5326  loss:  0.6897830963134766\n",
      "epoch:  69  accuracy:  0.5326  loss:  0.6897385716438293\n",
      "epoch:  70  accuracy:  0.5326  loss:  0.6896933317184448\n",
      "epoch:  71  accuracy:  0.5326  loss:  0.6896472573280334\n",
      "epoch:  72  accuracy:  0.5326  loss:  0.6896000504493713\n",
      "epoch:  73  accuracy:  0.5326  loss:  0.6895516514778137\n",
      "epoch:  74  accuracy:  0.5326  loss:  0.6895018219947815\n",
      "epoch:  75  accuracy:  0.5326  loss:  0.6894509792327881\n",
      "epoch:  76  accuracy:  0.5326  loss:  0.6893995404243469\n",
      "epoch:  77  accuracy:  0.5326  loss:  0.6893473863601685\n",
      "epoch:  78  accuracy:  0.5326  loss:  0.6892950534820557\n",
      "epoch:  79  accuracy:  0.5326  loss:  0.6892421245574951\n",
      "epoch:  80  accuracy:  0.5326  loss:  0.689187228679657\n",
      "epoch:  81  accuracy:  0.5326  loss:  0.6891313791275024\n",
      "epoch:  82  accuracy:  0.5326  loss:  0.6890752911567688\n",
      "epoch:  83  accuracy:  0.5326  loss:  0.6890186071395874\n",
      "epoch:  84  accuracy:  0.5326  loss:  0.6889612078666687\n",
      "epoch:  85  accuracy:  0.5326  loss:  0.6889028549194336\n",
      "epoch:  86  accuracy:  0.5326  loss:  0.6888435482978821\n",
      "epoch:  87  accuracy:  0.5326  loss:  0.6887832283973694\n",
      "epoch:  88  accuracy:  0.5326  loss:  0.6887223124504089\n",
      "epoch:  89  accuracy:  0.5326  loss:  0.688662052154541\n",
      "epoch:  90  accuracy:  0.5326  loss:  0.6885996460914612\n",
      "epoch:  91  accuracy:  0.5326  loss:  0.6885365843772888\n",
      "epoch:  92  accuracy:  0.5326  loss:  0.6884737610816956\n",
      "epoch:  93  accuracy:  0.5326  loss:  0.6884097456932068\n",
      "epoch:  94  accuracy:  0.5326  loss:  0.6883444786071777\n",
      "epoch:  95  accuracy:  0.5326  loss:  0.688279390335083\n",
      "epoch:  96  accuracy:  0.5326  loss:  0.6882139444351196\n",
      "epoch:  97  accuracy:  0.5326  loss:  0.688146710395813\n",
      "epoch:  98  accuracy:  0.5326  loss:  0.6880794167518616\n",
      "epoch:  99  accuracy:  0.5326  loss:  0.6880113482475281\n",
      "epoch:  100  accuracy:  0.5326  loss:  0.6879433393478394\n",
      "epoch:  101  accuracy:  0.5326  loss:  0.6878758072853088\n",
      "epoch:  102  accuracy:  0.5326  loss:  0.6878085732460022\n",
      "epoch:  103  accuracy:  0.5326  loss:  0.6877407431602478\n",
      "epoch:  104  accuracy:  0.5326  loss:  0.6876732110977173\n",
      "epoch:  105  accuracy:  0.5326  loss:  0.6876057386398315\n",
      "epoch:  106  accuracy:  0.5326  loss:  0.6875379681587219\n",
      "epoch:  107  accuracy:  0.5326  loss:  0.6874696612358093\n",
      "epoch:  108  accuracy:  0.5326  loss:  0.6874010562896729\n",
      "epoch:  109  accuracy:  0.5326  loss:  0.6873324513435364\n",
      "epoch:  110  accuracy:  0.5326  loss:  0.687263548374176\n",
      "epoch:  111  accuracy:  0.5326  loss:  0.687192440032959\n",
      "epoch:  112  accuracy:  0.5326  loss:  0.6871214509010315\n",
      "epoch:  113  accuracy:  0.5326  loss:  0.6870519518852234\n",
      "epoch:  114  accuracy:  0.5326  loss:  0.6869825720787048\n",
      "epoch:  115  accuracy:  0.5326  loss:  0.68690025806427\n",
      "epoch:  116  accuracy:  0.5326  loss:  0.6868121027946472\n",
      "epoch:  117  accuracy:  0.5326  loss:  0.6867274641990662\n",
      "epoch:  118  accuracy:  0.5326  loss:  0.6866399645805359\n",
      "epoch:  119  accuracy:  0.5326  loss:  0.6865535378456116\n",
      "epoch:  120  accuracy:  0.5326  loss:  0.6864741444587708\n",
      "epoch:  121  accuracy:  0.5326  loss:  0.686398983001709\n",
      "epoch:  122  accuracy:  0.5326  loss:  0.6863242387771606\n",
      "epoch:  123  accuracy:  0.5326  loss:  0.6862490773200989\n",
      "epoch:  124  accuracy:  0.5338  loss:  0.6861727833747864\n",
      "epoch:  125  accuracy:  0.5364666666666666  loss:  0.6860957741737366\n",
      "epoch:  126  accuracy:  0.5396  loss:  0.6860179901123047\n",
      "epoch:  127  accuracy:  0.5412  loss:  0.6859397292137146\n",
      "epoch:  128  accuracy:  0.5435666666666666  loss:  0.6858611106872559\n",
      "epoch:  129  accuracy:  0.5452666666666667  loss:  0.685781717300415\n",
      "epoch:  130  accuracy:  0.5469333333333334  loss:  0.6857017278671265\n",
      "epoch:  131  accuracy:  0.5492  loss:  0.6856215596199036\n",
      "epoch:  132  accuracy:  0.5511666666666667  loss:  0.6855409741401672\n",
      "epoch:  133  accuracy:  0.5520666666666667  loss:  0.6854598522186279\n",
      "epoch:  134  accuracy:  0.553  loss:  0.6853781938552856\n",
      "epoch:  135  accuracy:  0.5535666666666667  loss:  0.685296356678009\n",
      "epoch:  136  accuracy:  0.5547666666666666  loss:  0.6852144598960876\n",
      "epoch:  137  accuracy:  0.5552666666666667  loss:  0.6851320266723633\n",
      "epoch:  138  accuracy:  0.5561333333333334  loss:  0.6850490570068359\n",
      "epoch:  139  accuracy:  0.5580666666666667  loss:  0.6849656105041504\n",
      "epoch:  140  accuracy:  0.5588  loss:  0.6848818063735962\n",
      "epoch:  141  accuracy:  0.5589333333333333  loss:  0.684797465801239\n",
      "epoch:  142  accuracy:  0.5592  loss:  0.6847125887870789\n",
      "epoch:  143  accuracy:  0.5593666666666667  loss:  0.6846266984939575\n",
      "epoch:  144  accuracy:  0.5595333333333333  loss:  0.6845401525497437\n",
      "epoch:  145  accuracy:  0.5600333333333334  loss:  0.6844533085823059\n",
      "epoch:  146  accuracy:  0.5602666666666667  loss:  0.6843661665916443\n",
      "epoch:  147  accuracy:  0.561  loss:  0.6842785477638245\n",
      "epoch:  148  accuracy:  0.5623666666666667  loss:  0.6841902136802673\n",
      "epoch:  149  accuracy:  0.5629666666666666  loss:  0.6841011643409729\n",
      "epoch:  150  accuracy:  0.5633666666666667  loss:  0.6840115189552307\n",
      "epoch:  151  accuracy:  0.5638666666666666  loss:  0.6839210987091064\n",
      "epoch:  152  accuracy:  0.5648333333333333  loss:  0.6838300824165344\n",
      "epoch:  153  accuracy:  0.5651  loss:  0.6837384104728699\n",
      "epoch:  154  accuracy:  0.5658333333333333  loss:  0.683646023273468\n",
      "epoch:  155  accuracy:  0.5668333333333333  loss:  0.6835532784461975\n",
      "epoch:  156  accuracy:  0.5678333333333333  loss:  0.6834601759910583\n",
      "epoch:  157  accuracy:  0.5682333333333334  loss:  0.6833667755126953\n",
      "epoch:  158  accuracy:  0.5690333333333333  loss:  0.6832730770111084\n",
      "epoch:  159  accuracy:  0.5693333333333334  loss:  0.6831786632537842\n",
      "epoch:  160  accuracy:  0.5698666666666666  loss:  0.6830835938453674\n",
      "epoch:  161  accuracy:  0.5709666666666666  loss:  0.6829878687858582\n",
      "epoch:  162  accuracy:  0.5713666666666667  loss:  0.6828915476799011\n",
      "epoch:  163  accuracy:  0.572  loss:  0.6827949285507202\n",
      "epoch:  164  accuracy:  0.573  loss:  0.6826979517936707\n",
      "epoch:  165  accuracy:  0.5736333333333333  loss:  0.6826005578041077\n",
      "epoch:  166  accuracy:  0.5744333333333334  loss:  0.6825027465820312\n",
      "epoch:  167  accuracy:  0.5750333333333333  loss:  0.6824045181274414\n",
      "epoch:  168  accuracy:  0.5761  loss:  0.6823055148124695\n",
      "epoch:  169  accuracy:  0.5769666666666666  loss:  0.6822051405906677\n",
      "epoch:  170  accuracy:  0.5779333333333333  loss:  0.6821027398109436\n",
      "epoch:  171  accuracy:  0.5784  loss:  0.6819996237754822\n",
      "epoch:  172  accuracy:  0.5787666666666667  loss:  0.6818975210189819\n",
      "epoch:  173  accuracy:  0.5792333333333334  loss:  0.681795597076416\n",
      "epoch:  174  accuracy:  0.5790666666666666  loss:  0.6816933155059814\n",
      "epoch:  175  accuracy:  0.5792666666666667  loss:  0.68159019947052\n",
      "epoch:  176  accuracy:  0.5793333333333334  loss:  0.6814867854118347\n",
      "epoch:  177  accuracy:  0.5799333333333333  loss:  0.6813836097717285\n",
      "epoch:  178  accuracy:  0.5803333333333334  loss:  0.6812812089920044\n",
      "epoch:  179  accuracy:  0.5803666666666667  loss:  0.6811792850494385\n",
      "epoch:  180  accuracy:  0.5812333333333334  loss:  0.6810774207115173\n",
      "epoch:  181  accuracy:  0.5817  loss:  0.6809753775596619\n",
      "epoch:  182  accuracy:  0.5825666666666667  loss:  0.6808733940124512\n",
      "epoch:  183  accuracy:  0.5825666666666667  loss:  0.6807716488838196\n",
      "epoch:  184  accuracy:  0.5831  loss:  0.6806693077087402\n",
      "epoch:  185  accuracy:  0.5834  loss:  0.6805663108825684\n",
      "epoch:  186  accuracy:  0.5834666666666667  loss:  0.680463433265686\n",
      "epoch:  187  accuracy:  0.5834666666666667  loss:  0.6803610920906067\n",
      "epoch:  188  accuracy:  0.5833333333333334  loss:  0.6802585124969482\n",
      "epoch:  189  accuracy:  0.5835  loss:  0.6801562309265137\n",
      "epoch:  190  accuracy:  0.5842333333333334  loss:  0.6800548434257507\n",
      "epoch:  191  accuracy:  0.5840666666666666  loss:  0.6799537539482117\n",
      "epoch:  192  accuracy:  0.5843333333333334  loss:  0.6798531413078308\n",
      "epoch:  193  accuracy:  0.5841  loss:  0.6797523498535156\n",
      "epoch:  194  accuracy:  0.5841333333333333  loss:  0.6796513795852661\n",
      "epoch:  195  accuracy:  0.5848  loss:  0.679550290107727\n",
      "epoch:  196  accuracy:  0.5849333333333333  loss:  0.6794495582580566\n",
      "epoch:  197  accuracy:  0.5848666666666666  loss:  0.679348886013031\n",
      "epoch:  198  accuracy:  0.5849666666666666  loss:  0.6792477965354919\n",
      "epoch:  199  accuracy:  0.5847666666666667  loss:  0.6791462898254395\n",
      "epoch:  200  accuracy:  0.5851  loss:  0.6790450811386108\n",
      "epoch:  201  accuracy:  0.5851333333333333  loss:  0.6789430975914001\n",
      "epoch:  202  accuracy:  0.5851333333333333  loss:  0.6788409948348999\n",
      "epoch:  203  accuracy:  0.5851666666666666  loss:  0.6787393093109131\n",
      "epoch:  204  accuracy:  0.5856  loss:  0.6786383986473083\n",
      "epoch:  205  accuracy:  0.5854  loss:  0.6785385608673096\n",
      "epoch:  206  accuracy:  0.5852333333333334  loss:  0.6784393191337585\n",
      "epoch:  207  accuracy:  0.5852666666666667  loss:  0.678339958190918\n",
      "epoch:  208  accuracy:  0.5853666666666667  loss:  0.6782406568527222\n",
      "epoch:  209  accuracy:  0.5854333333333334  loss:  0.6781414747238159\n",
      "epoch:  210  accuracy:  0.5856333333333333  loss:  0.6780423521995544\n",
      "epoch:  211  accuracy:  0.5859666666666666  loss:  0.6779431700706482\n",
      "epoch:  212  accuracy:  0.5862  loss:  0.6778437495231628\n",
      "epoch:  213  accuracy:  0.5865333333333334  loss:  0.6777442693710327\n",
      "epoch:  214  accuracy:  0.5866666666666667  loss:  0.6776447296142578\n",
      "epoch:  215  accuracy:  0.5865666666666667  loss:  0.6775451302528381\n",
      "epoch:  216  accuracy:  0.5868333333333333  loss:  0.6774452924728394\n",
      "epoch:  217  accuracy:  0.5873666666666667  loss:  0.6773457527160645\n",
      "epoch:  218  accuracy:  0.5873666666666667  loss:  0.6772466897964478\n",
      "epoch:  219  accuracy:  0.5870333333333333  loss:  0.6771476864814758\n",
      "epoch:  220  accuracy:  0.5874  loss:  0.6770484447479248\n",
      "epoch:  221  accuracy:  0.5871333333333333  loss:  0.6769492030143738\n",
      "epoch:  222  accuracy:  0.5877  loss:  0.6768509149551392\n",
      "epoch:  223  accuracy:  0.5874666666666667  loss:  0.6767539381980896\n",
      "epoch:  224  accuracy:  0.5883  loss:  0.6766576766967773\n",
      "epoch:  225  accuracy:  0.5875333333333334  loss:  0.6765591502189636\n",
      "epoch:  226  accuracy:  0.5887333333333333  loss:  0.6764557361602783\n",
      "epoch:  227  accuracy:  0.5884666666666667  loss:  0.6763526201248169\n",
      "epoch:  228  accuracy:  0.5883666666666667  loss:  0.6762553453445435\n",
      "epoch:  229  accuracy:  0.589  loss:  0.6761599779129028\n",
      "epoch:  230  accuracy:  0.5883  loss:  0.6760590076446533\n",
      "epoch:  231  accuracy:  0.5895  loss:  0.6759557723999023\n",
      "epoch:  232  accuracy:  0.5896  loss:  0.6758562326431274\n",
      "epoch:  233  accuracy:  0.5882333333333334  loss:  0.6757588386535645\n",
      "epoch:  234  accuracy:  0.5896666666666667  loss:  0.6756582260131836\n",
      "epoch:  235  accuracy:  0.5888333333333333  loss:  0.6755552291870117\n",
      "epoch:  236  accuracy:  0.5898333333333333  loss:  0.6754536628723145\n",
      "epoch:  237  accuracy:  0.5904666666666667  loss:  0.675354540348053\n",
      "epoch:  238  accuracy:  0.5891666666666666  loss:  0.6752554774284363\n",
      "epoch:  239  accuracy:  0.5907333333333333  loss:  0.6751546859741211\n",
      "epoch:  240  accuracy:  0.5893666666666667  loss:  0.6750521063804626\n",
      "epoch:  241  accuracy:  0.5897666666666667  loss:  0.6749505400657654\n",
      "epoch:  242  accuracy:  0.5904  loss:  0.6748506426811218\n",
      "epoch:  243  accuracy:  0.5896  loss:  0.6747512817382812\n",
      "epoch:  244  accuracy:  0.5906666666666667  loss:  0.674652099609375\n",
      "epoch:  245  accuracy:  0.5901  loss:  0.6745513677597046\n",
      "epoch:  246  accuracy:  0.5907666666666667  loss:  0.6744497418403625\n",
      "epoch:  247  accuracy:  0.5906333333333333  loss:  0.6743485331535339\n",
      "epoch:  248  accuracy:  0.5907666666666667  loss:  0.6742479205131531\n",
      "epoch:  249  accuracy:  0.5907  loss:  0.6741482019424438\n",
      "epoch:  250  accuracy:  0.5906666666666667  loss:  0.6740487217903137\n",
      "epoch:  251  accuracy:  0.5918333333333333  loss:  0.6739499568939209\n",
      "epoch:  252  accuracy:  0.5901333333333333  loss:  0.6738517880439758\n",
      "epoch:  253  accuracy:  0.5923333333333334  loss:  0.6737544536590576\n",
      "epoch:  254  accuracy:  0.5905333333333334  loss:  0.6736548542976379\n",
      "epoch:  255  accuracy:  0.5924  loss:  0.6735531091690063\n",
      "epoch:  256  accuracy:  0.591  loss:  0.6734506487846375\n",
      "epoch:  257  accuracy:  0.5917333333333333  loss:  0.6733492016792297\n",
      "epoch:  258  accuracy:  0.5919333333333333  loss:  0.6732500195503235\n",
      "epoch:  259  accuracy:  0.5911  loss:  0.6731529831886292\n",
      "epoch:  260  accuracy:  0.5931  loss:  0.6730583906173706\n",
      "epoch:  261  accuracy:  0.5900333333333333  loss:  0.6729646921157837\n",
      "epoch:  262  accuracy:  0.5935333333333334  loss:  0.6728704571723938\n",
      "epoch:  263  accuracy:  0.5902666666666667  loss:  0.6727709770202637\n",
      "epoch:  264  accuracy:  0.5933  loss:  0.6726686358451843\n",
      "epoch:  265  accuracy:  0.5921  loss:  0.6725703477859497\n",
      "epoch:  266  accuracy:  0.5908  loss:  0.6724779605865479\n",
      "epoch:  267  accuracy:  0.5941666666666666  loss:  0.6723862290382385\n",
      "epoch:  268  accuracy:  0.5907666666666667  loss:  0.6722902655601501\n",
      "epoch:  269  accuracy:  0.5938333333333333  loss:  0.6721914410591125\n",
      "epoch:  270  accuracy:  0.5921333333333333  loss:  0.6720935702323914\n",
      "epoch:  271  accuracy:  0.5919  loss:  0.6719990968704224\n",
      "epoch:  272  accuracy:  0.5938333333333333  loss:  0.6719064116477966\n",
      "epoch:  273  accuracy:  0.5911333333333333  loss:  0.6718138456344604\n",
      "epoch:  274  accuracy:  0.5936666666666667  loss:  0.6717192530632019\n",
      "epoch:  275  accuracy:  0.5914  loss:  0.6716232895851135\n",
      "epoch:  276  accuracy:  0.5939333333333333  loss:  0.6715272665023804\n",
      "epoch:  277  accuracy:  0.5925  loss:  0.6714321970939636\n",
      "epoch:  278  accuracy:  0.5931666666666666  loss:  0.6713380217552185\n",
      "epoch:  279  accuracy:  0.5936333333333333  loss:  0.6712454557418823\n",
      "epoch:  280  accuracy:  0.5920666666666666  loss:  0.6711539030075073\n",
      "epoch:  281  accuracy:  0.5943666666666667  loss:  0.6710636019706726\n",
      "epoch:  282  accuracy:  0.5910333333333333  loss:  0.6709747910499573\n",
      "epoch:  283  accuracy:  0.5953  loss:  0.6708882451057434\n",
      "epoch:  284  accuracy:  0.5906  loss:  0.6708002090454102\n",
      "epoch:  285  accuracy:  0.5959333333333333  loss:  0.6707081198692322\n",
      "epoch:  286  accuracy:  0.5912333333333334  loss:  0.670611560344696\n",
      "epoch:  287  accuracy:  0.5949333333333333  loss:  0.6705135703086853\n",
      "epoch:  288  accuracy:  0.5937666666666667  loss:  0.6704206466674805\n",
      "epoch:  289  accuracy:  0.5921666666666666  loss:  0.6703367829322815\n",
      "epoch:  290  accuracy:  0.5961333333333333  loss:  0.6702568531036377\n",
      "epoch:  291  accuracy:  0.5920333333333333  loss:  0.6701723337173462\n",
      "epoch:  292  accuracy:  0.5961333333333333  loss:  0.670081377029419\n",
      "epoch:  293  accuracy:  0.5933666666666667  loss:  0.6699886918067932\n",
      "epoch:  294  accuracy:  0.5938333333333333  loss:  0.6699017882347107\n",
      "epoch:  295  accuracy:  0.5963666666666667  loss:  0.6698213815689087\n",
      "epoch:  296  accuracy:  0.5932333333333333  loss:  0.6697418689727783\n",
      "epoch:  297  accuracy:  0.5965666666666667  loss:  0.6696575880050659\n",
      "epoch:  298  accuracy:  0.5939666666666666  loss:  0.6695692539215088\n",
      "epoch:  299  accuracy:  0.5959333333333333  loss:  0.669481635093689\n",
      "epoch:  300  accuracy:  0.5958333333333333  loss:  0.6693985462188721\n",
      "epoch:  301  accuracy:  0.594  loss:  0.6693199872970581\n",
      "epoch:  302  accuracy:  0.5976333333333333  loss:  0.6692430973052979\n",
      "epoch:  303  accuracy:  0.5937666666666667  loss:  0.669163167476654\n",
      "epoch:  304  accuracy:  0.5978666666666667  loss:  0.6690788269042969\n",
      "epoch:  305  accuracy:  0.5945666666666667  loss:  0.6689938902854919\n",
      "epoch:  306  accuracy:  0.5966  loss:  0.6689099073410034\n",
      "epoch:  307  accuracy:  0.5964333333333334  loss:  0.6688293218612671\n",
      "epoch:  308  accuracy:  0.5953333333333334  loss:  0.6687519550323486\n",
      "epoch:  309  accuracy:  0.5981333333333333  loss:  0.6686764359474182\n",
      "epoch:  310  accuracy:  0.5951333333333333  loss:  0.6686030030250549\n",
      "epoch:  311  accuracy:  0.5988333333333333  loss:  0.6685307621955872\n",
      "epoch:  312  accuracy:  0.5949  loss:  0.6684561371803284\n",
      "epoch:  313  accuracy:  0.599  loss:  0.6683774590492249\n",
      "epoch:  314  accuracy:  0.5957  loss:  0.6682940721511841\n",
      "epoch:  315  accuracy:  0.5984666666666667  loss:  0.6682119965553284\n",
      "epoch:  316  accuracy:  0.5980666666666666  loss:  0.6681352853775024\n",
      "epoch:  317  accuracy:  0.5964333333333334  loss:  0.6680632829666138\n",
      "epoch:  318  accuracy:  0.5993  loss:  0.667995035648346\n",
      "epoch:  319  accuracy:  0.5954666666666667  loss:  0.6679278612136841\n",
      "epoch:  320  accuracy:  0.5995333333333334  loss:  0.6678604483604431\n",
      "epoch:  321  accuracy:  0.5955666666666667  loss:  0.6677872538566589\n",
      "epoch:  322  accuracy:  0.5998  loss:  0.6677098274230957\n",
      "epoch:  323  accuracy:  0.5976  loss:  0.6676276922225952\n",
      "epoch:  324  accuracy:  0.5988333333333333  loss:  0.6675530672073364\n",
      "epoch:  325  accuracy:  0.5994666666666667  loss:  0.6674872636795044\n",
      "epoch:  326  accuracy:  0.5970333333333333  loss:  0.6674225926399231\n",
      "epoch:  327  accuracy:  0.6  loss:  0.6673573851585388\n",
      "epoch:  328  accuracy:  0.5970333333333333  loss:  0.6672859191894531\n",
      "epoch:  329  accuracy:  0.5997333333333333  loss:  0.6672088503837585\n",
      "epoch:  330  accuracy:  0.5993333333333334  loss:  0.6671333312988281\n",
      "epoch:  331  accuracy:  0.6  loss:  0.66706383228302\n",
      "epoch:  332  accuracy:  0.6001  loss:  0.667000412940979\n",
      "epoch:  333  accuracy:  0.598  loss:  0.6669400334358215\n",
      "epoch:  334  accuracy:  0.6008333333333333  loss:  0.6668804883956909\n",
      "epoch:  335  accuracy:  0.5975  loss:  0.6668144464492798\n",
      "epoch:  336  accuracy:  0.6008666666666667  loss:  0.6667430996894836\n",
      "epoch:  337  accuracy:  0.5990333333333333  loss:  0.6666668057441711\n",
      "epoch:  338  accuracy:  0.6009  loss:  0.6665955185890198\n",
      "epoch:  339  accuracy:  0.6010666666666666  loss:  0.6665321588516235\n",
      "epoch:  340  accuracy:  0.5993333333333334  loss:  0.6664739847183228\n",
      "epoch:  341  accuracy:  0.6016333333333334  loss:  0.6664156317710876\n",
      "epoch:  342  accuracy:  0.5989666666666666  loss:  0.6663532853126526\n",
      "epoch:  343  accuracy:  0.6017666666666667  loss:  0.6662849187850952\n",
      "epoch:  344  accuracy:  0.5999666666666666  loss:  0.6662119030952454\n",
      "epoch:  345  accuracy:  0.6019  loss:  0.666143000125885\n",
      "epoch:  346  accuracy:  0.6016  loss:  0.666081964969635\n",
      "epoch:  347  accuracy:  0.6003333333333334  loss:  0.6660246253013611\n",
      "epoch:  348  accuracy:  0.6022333333333333  loss:  0.6659669280052185\n",
      "epoch:  349  accuracy:  0.6001666666666666  loss:  0.665904700756073\n",
      "epoch:  350  accuracy:  0.6023333333333334  loss:  0.6658393144607544\n",
      "epoch:  351  accuracy:  0.6013333333333334  loss:  0.6657726764678955\n",
      "epoch:  352  accuracy:  0.6020333333333333  loss:  0.6657071709632874\n",
      "epoch:  353  accuracy:  0.6020666666666666  loss:  0.665644645690918\n",
      "epoch:  354  accuracy:  0.6017666666666667  loss:  0.6655851602554321\n",
      "epoch:  355  accuracy:  0.6019  loss:  0.6655274629592896\n",
      "epoch:  356  accuracy:  0.6016  loss:  0.6654700636863708\n",
      "epoch:  357  accuracy:  0.6023666666666667  loss:  0.6654115319252014\n",
      "epoch:  358  accuracy:  0.6017  loss:  0.6653514504432678\n",
      "epoch:  359  accuracy:  0.6026666666666667  loss:  0.665291428565979\n",
      "epoch:  360  accuracy:  0.6024666666666667  loss:  0.6652311682701111\n",
      "epoch:  361  accuracy:  0.6025  loss:  0.6651708483695984\n",
      "epoch:  362  accuracy:  0.6024333333333334  loss:  0.6651111245155334\n",
      "epoch:  363  accuracy:  0.6026  loss:  0.6650521755218506\n",
      "epoch:  364  accuracy:  0.6026333333333334  loss:  0.6649942398071289\n",
      "epoch:  365  accuracy:  0.6028333333333333  loss:  0.664936363697052\n",
      "epoch:  366  accuracy:  0.6027666666666667  loss:  0.6648790836334229\n",
      "epoch:  367  accuracy:  0.6028333333333333  loss:  0.6648221015930176\n",
      "epoch:  368  accuracy:  0.6030666666666666  loss:  0.6647656559944153\n",
      "epoch:  369  accuracy:  0.6029666666666667  loss:  0.6647093892097473\n",
      "epoch:  370  accuracy:  0.6035666666666667  loss:  0.6646532416343689\n",
      "epoch:  371  accuracy:  0.6030333333333333  loss:  0.6645980477333069\n",
      "epoch:  372  accuracy:  0.6036666666666667  loss:  0.6645436882972717\n",
      "epoch:  373  accuracy:  0.6033  loss:  0.664491593837738\n",
      "epoch:  374  accuracy:  0.6055666666666667  loss:  0.664447546005249\n",
      "epoch:  375  accuracy:  0.6018  loss:  0.6644341945648193\n",
      "epoch:  376  accuracy:  0.6067666666666667  loss:  0.6644918322563171\n",
      "epoch:  377  accuracy:  0.5995666666666667  loss:  0.664536714553833\n",
      "epoch:  378  accuracy:  0.6067333333333333  loss:  0.6643548607826233\n",
      "epoch:  379  accuracy:  0.605  loss:  0.6641688942909241\n",
      "epoch:  380  accuracy:  0.6015333333333334  loss:  0.6642670035362244\n",
      "epoch:  381  accuracy:  0.6069666666666667  loss:  0.6641688346862793\n",
      "epoch:  382  accuracy:  0.6061333333333333  loss:  0.6640185713768005\n",
      "epoch:  383  accuracy:  0.6022  loss:  0.6640822887420654\n",
      "epoch:  384  accuracy:  0.6068  loss:  0.6639566421508789\n",
      "epoch:  385  accuracy:  0.6066666666666667  loss:  0.6638882756233215\n",
      "epoch:  386  accuracy:  0.6026333333333334  loss:  0.6639079451560974\n",
      "epoch:  387  accuracy:  0.6065333333333334  loss:  0.6637704372406006\n",
      "epoch:  388  accuracy:  0.6070333333333333  loss:  0.6637639403343201\n",
      "epoch:  389  accuracy:  0.6035666666666667  loss:  0.6637170910835266\n",
      "epoch:  390  accuracy:  0.6047333333333333  loss:  0.6636179685592651\n",
      "epoch:  391  accuracy:  0.6072333333333333  loss:  0.6636256575584412\n",
      "epoch:  392  accuracy:  0.6045666666666667  loss:  0.6635311245918274\n",
      "epoch:  393  accuracy:  0.6047333333333333  loss:  0.6634886264801025\n",
      "epoch:  394  accuracy:  0.6070666666666666  loss:  0.6634624004364014\n",
      "epoch:  395  accuracy:  0.6067666666666667  loss:  0.6633738875389099\n",
      "epoch:  396  accuracy:  0.6050333333333333  loss:  0.663360595703125\n",
      "epoch:  397  accuracy:  0.6068333333333333  loss:  0.6632962226867676\n",
      "epoch:  398  accuracy:  0.6066666666666667  loss:  0.6632410287857056\n",
      "epoch:  399  accuracy:  0.6052333333333333  loss:  0.6632192730903625\n",
      "epoch:  400  accuracy:  0.6066  loss:  0.6631454229354858\n",
      "epoch:  401  accuracy:  0.6071  loss:  0.6631124019622803\n",
      "epoch:  402  accuracy:  0.6055333333333334  loss:  0.6630695462226868\n",
      "epoch:  403  accuracy:  0.6069666666666667  loss:  0.6630064249038696\n",
      "epoch:  404  accuracy:  0.6072666666666666  loss:  0.6629759669303894\n",
      "epoch:  405  accuracy:  0.6066  loss:  0.6629223823547363\n",
      "epoch:  406  accuracy:  0.6068666666666667  loss:  0.6628749966621399\n",
      "epoch:  407  accuracy:  0.6074333333333334  loss:  0.6628400087356567\n",
      "epoch:  408  accuracy:  0.6072  loss:  0.6627843976020813\n",
      "epoch:  409  accuracy:  0.6067666666666667  loss:  0.6627457141876221\n",
      "epoch:  410  accuracy:  0.6073333333333333  loss:  0.6627041697502136\n",
      "epoch:  411  accuracy:  0.6072333333333333  loss:  0.6626520156860352\n",
      "epoch:  412  accuracy:  0.6068333333333333  loss:  0.6626152396202087\n",
      "epoch:  413  accuracy:  0.6070666666666666  loss:  0.6625707149505615\n",
      "epoch:  414  accuracy:  0.6072666666666666  loss:  0.6625221371650696\n",
      "epoch:  415  accuracy:  0.6069  loss:  0.6624851822853088\n",
      "epoch:  416  accuracy:  0.6073333333333333  loss:  0.6624400019645691\n",
      "epoch:  417  accuracy:  0.6073333333333333  loss:  0.6623937487602234\n",
      "epoch:  418  accuracy:  0.6069  loss:  0.6623549461364746\n",
      "epoch:  419  accuracy:  0.6077333333333333  loss:  0.6623103022575378\n",
      "epoch:  420  accuracy:  0.6078333333333333  loss:  0.6622660160064697\n",
      "epoch:  421  accuracy:  0.6070333333333333  loss:  0.6622269153594971\n",
      "epoch:  422  accuracy:  0.6082333333333333  loss:  0.6621834635734558\n",
      "epoch:  423  accuracy:  0.6080333333333333  loss:  0.6621397733688354\n",
      "epoch:  424  accuracy:  0.6074333333333334  loss:  0.662100613117218\n",
      "epoch:  425  accuracy:  0.6086666666666667  loss:  0.6620591282844543\n",
      "epoch:  426  accuracy:  0.6082  loss:  0.6620156764984131\n",
      "epoch:  427  accuracy:  0.6079333333333333  loss:  0.6619753837585449\n",
      "epoch:  428  accuracy:  0.6087666666666667  loss:  0.6619349718093872\n",
      "epoch:  429  accuracy:  0.6083  loss:  0.6618919372558594\n",
      "epoch:  430  accuracy:  0.6084666666666667  loss:  0.6618503928184509\n",
      "epoch:  431  accuracy:  0.6091333333333333  loss:  0.6618109345436096\n",
      "epoch:  432  accuracy:  0.6086  loss:  0.6617691516876221\n",
      "epoch:  433  accuracy:  0.609  loss:  0.6617268323898315\n",
      "epoch:  434  accuracy:  0.6090333333333333  loss:  0.6616864204406738\n",
      "epoch:  435  accuracy:  0.6084  loss:  0.6616470217704773\n",
      "epoch:  436  accuracy:  0.6090333333333333  loss:  0.6616061329841614\n",
      "epoch:  437  accuracy:  0.6087666666666667  loss:  0.661565363407135\n",
      "epoch:  438  accuracy:  0.6089666666666667  loss:  0.6615256667137146\n",
      "epoch:  439  accuracy:  0.609  loss:  0.6614862084388733\n",
      "epoch:  440  accuracy:  0.6088  loss:  0.6614460945129395\n",
      "epoch:  441  accuracy:  0.6087333333333333  loss:  0.6614063382148743\n",
      "epoch:  442  accuracy:  0.6089  loss:  0.6613674759864807\n",
      "epoch:  443  accuracy:  0.6088  loss:  0.661328911781311\n",
      "epoch:  444  accuracy:  0.6090333333333333  loss:  0.6612896919250488\n",
      "epoch:  445  accuracy:  0.6088666666666667  loss:  0.6612503528594971\n",
      "epoch:  446  accuracy:  0.6089666666666667  loss:  0.6612111926078796\n",
      "epoch:  447  accuracy:  0.609  loss:  0.6611717939376831\n",
      "epoch:  448  accuracy:  0.6089666666666667  loss:  0.6611317992210388\n",
      "epoch:  449  accuracy:  0.6091  loss:  0.6610862016677856\n",
      "epoch:  450  accuracy:  0.6088666666666667  loss:  0.6610365509986877\n",
      "epoch:  451  accuracy:  0.6092  loss:  0.6609805822372437\n",
      "epoch:  452  accuracy:  0.6089666666666667  loss:  0.6609293222427368\n",
      "epoch:  453  accuracy:  0.6088666666666667  loss:  0.6608921885490417\n",
      "epoch:  454  accuracy:  0.6089  loss:  0.6608545780181885\n",
      "epoch:  455  accuracy:  0.6092333333333333  loss:  0.6608157157897949\n",
      "epoch:  456  accuracy:  0.6089666666666667  loss:  0.6607770323753357\n",
      "epoch:  457  accuracy:  0.6089  loss:  0.6607385277748108\n",
      "epoch:  458  accuracy:  0.6092666666666666  loss:  0.6607006192207336\n",
      "epoch:  459  accuracy:  0.609  loss:  0.6606634259223938\n",
      "epoch:  460  accuracy:  0.6093333333333333  loss:  0.6606261134147644\n",
      "epoch:  461  accuracy:  0.6091333333333333  loss:  0.660588800907135\n",
      "epoch:  462  accuracy:  0.6097666666666667  loss:  0.6605510711669922\n",
      "epoch:  463  accuracy:  0.6093666666666666  loss:  0.6605125069618225\n",
      "epoch:  464  accuracy:  0.6095666666666667  loss:  0.6604738235473633\n",
      "epoch:  465  accuracy:  0.6095333333333334  loss:  0.6604363918304443\n",
      "epoch:  466  accuracy:  0.6094333333333334  loss:  0.6603989601135254\n",
      "epoch:  467  accuracy:  0.6095  loss:  0.6603620052337646\n",
      "epoch:  468  accuracy:  0.6094  loss:  0.6603254675865173\n",
      "epoch:  469  accuracy:  0.6097  loss:  0.6602895855903625\n",
      "epoch:  470  accuracy:  0.6093  loss:  0.6602570414543152\n",
      "epoch:  471  accuracy:  0.6101666666666666  loss:  0.6602317690849304\n",
      "epoch:  472  accuracy:  0.6089333333333333  loss:  0.6602247357368469\n",
      "epoch:  473  accuracy:  0.6107  loss:  0.6602432727813721\n",
      "epoch:  474  accuracy:  0.6076666666666667  loss:  0.6602885723114014\n",
      "epoch:  475  accuracy:  0.6122  loss:  0.6602993607521057\n",
      "epoch:  476  accuracy:  0.6081666666666666  loss:  0.6601638793945312\n",
      "epoch:  477  accuracy:  0.6102  loss:  0.6600072979927063\n",
      "epoch:  478  accuracy:  0.6108666666666667  loss:  0.6600032448768616\n",
      "epoch:  479  accuracy:  0.6082666666666666  loss:  0.6600587964057922\n",
      "epoch:  480  accuracy:  0.611  loss:  0.6599884629249573\n",
      "epoch:  481  accuracy:  0.6099666666666667  loss:  0.6598699688911438\n",
      "epoch:  482  accuracy:  0.6096333333333334  loss:  0.6598682999610901\n",
      "epoch:  483  accuracy:  0.6109666666666667  loss:  0.6598859429359436\n",
      "epoch:  484  accuracy:  0.6098333333333333  loss:  0.6598027348518372\n",
      "epoch:  485  accuracy:  0.6098666666666667  loss:  0.6597383618354797\n",
      "epoch:  486  accuracy:  0.6109666666666667  loss:  0.6597533822059631\n",
      "epoch:  487  accuracy:  0.6092333333333333  loss:  0.659724771976471\n",
      "epoch:  488  accuracy:  0.6104333333333334  loss:  0.659646213054657\n",
      "epoch:  489  accuracy:  0.6108  loss:  0.6596220135688782\n",
      "epoch:  490  accuracy:  0.6094333333333334  loss:  0.6596205830574036\n",
      "epoch:  491  accuracy:  0.6111333333333333  loss:  0.6595658659934998\n",
      "epoch:  492  accuracy:  0.6105  loss:  0.6595122218132019\n",
      "epoch:  493  accuracy:  0.6107  loss:  0.6594986915588379\n",
      "epoch:  494  accuracy:  0.6110333333333333  loss:  0.6594753861427307\n",
      "epoch:  495  accuracy:  0.6109666666666667  loss:  0.6594231128692627\n",
      "epoch:  496  accuracy:  0.6107  loss:  0.6593881845474243\n",
      "epoch:  497  accuracy:  0.6112333333333333  loss:  0.6593731641769409\n",
      "epoch:  498  accuracy:  0.6108666666666667  loss:  0.6593387722969055\n",
      "epoch:  499  accuracy:  0.6103666666666666  loss:  0.659293532371521\n",
      "epoch:  500  accuracy:  0.6107666666666667  loss:  0.6592649817466736\n",
      "epoch:  501  accuracy:  0.6112333333333333  loss:  0.659242570400238\n",
      "epoch:  502  accuracy:  0.6107666666666667  loss:  0.6592069268226624\n",
      "epoch:  503  accuracy:  0.6113333333333333  loss:  0.6591704487800598\n",
      "epoch:  504  accuracy:  0.6113333333333333  loss:  0.6591432094573975\n",
      "epoch:  505  accuracy:  0.6112333333333333  loss:  0.6591179966926575\n",
      "epoch:  506  accuracy:  0.6114  loss:  0.659086287021637\n",
      "epoch:  507  accuracy:  0.6109666666666667  loss:  0.6590509414672852\n",
      "epoch:  508  accuracy:  0.6110333333333333  loss:  0.6590209603309631\n",
      "epoch:  509  accuracy:  0.6115666666666667  loss:  0.6589955687522888\n",
      "epoch:  510  accuracy:  0.6116  loss:  0.6589667201042175\n",
      "epoch:  511  accuracy:  0.6116666666666667  loss:  0.6589337587356567\n",
      "epoch:  512  accuracy:  0.6117333333333334  loss:  0.6589013934135437\n",
      "epoch:  513  accuracy:  0.6118333333333333  loss:  0.6588726043701172\n",
      "epoch:  514  accuracy:  0.6115  loss:  0.6588461399078369\n",
      "epoch:  515  accuracy:  0.6117333333333334  loss:  0.6588175892829895\n",
      "epoch:  516  accuracy:  0.612  loss:  0.6587849855422974\n",
      "epoch:  517  accuracy:  0.6120333333333333  loss:  0.6587529182434082\n",
      "epoch:  518  accuracy:  0.6120666666666666  loss:  0.6587229371070862\n",
      "epoch:  519  accuracy:  0.6121  loss:  0.6586946845054626\n",
      "epoch:  520  accuracy:  0.612  loss:  0.6586668491363525\n",
      "epoch:  521  accuracy:  0.6121333333333333  loss:  0.6586384177207947\n",
      "epoch:  522  accuracy:  0.6122333333333333  loss:  0.6586090922355652\n",
      "epoch:  523  accuracy:  0.6123  loss:  0.6585786938667297\n",
      "epoch:  524  accuracy:  0.6121333333333333  loss:  0.6585487127304077\n",
      "epoch:  525  accuracy:  0.6123333333333333  loss:  0.6585196852684021\n",
      "epoch:  526  accuracy:  0.6123666666666666  loss:  0.6584911942481995\n",
      "epoch:  527  accuracy:  0.6126333333333334  loss:  0.6584636569023132\n",
      "epoch:  528  accuracy:  0.6122333333333333  loss:  0.658435583114624\n",
      "epoch:  529  accuracy:  0.6125333333333334  loss:  0.6584070324897766\n",
      "epoch:  530  accuracy:  0.6124666666666667  loss:  0.6583782434463501\n",
      "epoch:  531  accuracy:  0.6127  loss:  0.6583497524261475\n",
      "epoch:  532  accuracy:  0.6125333333333334  loss:  0.6583216190338135\n",
      "epoch:  533  accuracy:  0.6124333333333334  loss:  0.6582935452461243\n",
      "epoch:  534  accuracy:  0.6127333333333334  loss:  0.6582657098770142\n",
      "epoch:  535  accuracy:  0.6123666666666666  loss:  0.6582375764846802\n",
      "epoch:  536  accuracy:  0.6125666666666667  loss:  0.658210039138794\n",
      "epoch:  537  accuracy:  0.6125333333333334  loss:  0.6581829786300659\n",
      "epoch:  538  accuracy:  0.6129666666666667  loss:  0.6581571102142334\n",
      "epoch:  539  accuracy:  0.6127333333333334  loss:  0.6581329703330994\n",
      "epoch:  540  accuracy:  0.6129666666666667  loss:  0.6581113338470459\n",
      "epoch:  541  accuracy:  0.6127333333333334  loss:  0.6580922603607178\n",
      "epoch:  542  accuracy:  0.6133  loss:  0.6580748558044434\n",
      "epoch:  543  accuracy:  0.6122  loss:  0.6580567955970764\n",
      "epoch:  544  accuracy:  0.6136333333333334  loss:  0.6580406427383423\n",
      "epoch:  545  accuracy:  0.6123  loss:  0.6580116152763367\n",
      "epoch:  546  accuracy:  0.6135  loss:  0.6579793095588684\n",
      "epoch:  547  accuracy:  0.6127  loss:  0.6579336524009705\n",
      "epoch:  548  accuracy:  0.6132  loss:  0.6578912138938904\n",
      "epoch:  549  accuracy:  0.6129666666666667  loss:  0.6578572988510132\n",
      "epoch:  550  accuracy:  0.6131  loss:  0.6578331589698792\n",
      "epoch:  551  accuracy:  0.6134666666666667  loss:  0.6578161716461182\n",
      "epoch:  552  accuracy:  0.6127333333333334  loss:  0.6578007936477661\n",
      "epoch:  553  accuracy:  0.6136666666666667  loss:  0.6577855348587036\n",
      "epoch:  554  accuracy:  0.6127333333333334  loss:  0.6577596664428711\n",
      "epoch:  555  accuracy:  0.6136666666666667  loss:  0.6577290892601013\n",
      "epoch:  556  accuracy:  0.6128666666666667  loss:  0.6576908230781555\n",
      "epoch:  557  accuracy:  0.6134333333333334  loss:  0.6576549410820007\n",
      "epoch:  558  accuracy:  0.6131666666666666  loss:  0.6576250791549683\n",
      "epoch:  559  accuracy:  0.6133333333333333  loss:  0.6576010584831238\n",
      "epoch:  560  accuracy:  0.6131666666666666  loss:  0.6575806140899658\n",
      "epoch:  561  accuracy:  0.6132  loss:  0.657562255859375\n",
      "epoch:  562  accuracy:  0.6139666666666667  loss:  0.65754234790802\n",
      "epoch:  563  accuracy:  0.6130333333333333  loss:  0.6575179696083069\n",
      "epoch:  564  accuracy:  0.6138333333333333  loss:  0.6574913859367371\n",
      "epoch:  565  accuracy:  0.6133666666666666  loss:  0.6574609279632568\n",
      "epoch:  566  accuracy:  0.6136666666666667  loss:  0.6574315428733826\n",
      "epoch:  567  accuracy:  0.6137333333333334  loss:  0.657401978969574\n",
      "epoch:  568  accuracy:  0.6132333333333333  loss:  0.657374382019043\n",
      "epoch:  569  accuracy:  0.6136  loss:  0.6573486924171448\n",
      "epoch:  570  accuracy:  0.6135333333333334  loss:  0.6573248505592346\n",
      "epoch:  571  accuracy:  0.6135333333333334  loss:  0.6573021411895752\n",
      "epoch:  572  accuracy:  0.6135666666666667  loss:  0.6572810411453247\n",
      "epoch:  573  accuracy:  0.6142  loss:  0.6572644710540771\n",
      "epoch:  574  accuracy:  0.6135333333333334  loss:  0.6572511196136475\n",
      "epoch:  575  accuracy:  0.6149  loss:  0.6572484374046326\n",
      "epoch:  576  accuracy:  0.6135333333333334  loss:  0.6572445631027222\n",
      "epoch:  577  accuracy:  0.6150666666666667  loss:  0.6572479009628296\n",
      "epoch:  578  accuracy:  0.6134666666666667  loss:  0.6572354435920715\n",
      "epoch:  579  accuracy:  0.6150333333333333  loss:  0.6572040915489197\n",
      "epoch:  580  accuracy:  0.6136666666666667  loss:  0.657137393951416\n",
      "epoch:  581  accuracy:  0.6145333333333334  loss:  0.6570767164230347\n",
      "epoch:  582  accuracy:  0.6137333333333334  loss:  0.6570366621017456\n",
      "epoch:  583  accuracy:  0.614  loss:  0.6570239067077637\n",
      "epoch:  584  accuracy:  0.615  loss:  0.6570274233818054\n",
      "epoch:  585  accuracy:  0.6139  loss:  0.6570209264755249\n",
      "epoch:  586  accuracy:  0.6151333333333333  loss:  0.6569970846176147\n",
      "epoch:  587  accuracy:  0.6143  loss:  0.6569499969482422\n",
      "epoch:  588  accuracy:  0.6144333333333334  loss:  0.6569061279296875\n",
      "epoch:  589  accuracy:  0.6139666666666667  loss:  0.6568748354911804\n",
      "epoch:  590  accuracy:  0.6137333333333334  loss:  0.6568583250045776\n",
      "epoch:  591  accuracy:  0.6145666666666667  loss:  0.656850278377533\n",
      "epoch:  592  accuracy:  0.6144  loss:  0.6568363308906555\n",
      "epoch:  593  accuracy:  0.6150666666666667  loss:  0.6568123698234558\n",
      "epoch:  594  accuracy:  0.6146  loss:  0.6567785143852234\n",
      "epoch:  595  accuracy:  0.6147333333333334  loss:  0.6567450165748596\n",
      "epoch:  596  accuracy:  0.6143666666666666  loss:  0.6567155122756958\n",
      "epoch:  597  accuracy:  0.6142  loss:  0.6566939949989319\n",
      "epoch:  598  accuracy:  0.6148333333333333  loss:  0.6566782593727112\n",
      "epoch:  599  accuracy:  0.6145666666666667  loss:  0.6566639542579651\n",
      "epoch:  600  accuracy:  0.6149  loss:  0.6566458344459534\n",
      "epoch:  601  accuracy:  0.6145  loss:  0.6566225290298462\n",
      "epoch:  602  accuracy:  0.6149333333333333  loss:  0.6565941572189331\n",
      "epoch:  603  accuracy:  0.6145  loss:  0.6565646529197693\n",
      "epoch:  604  accuracy:  0.6144333333333334  loss:  0.6565365791320801\n",
      "epoch:  605  accuracy:  0.6143  loss:  0.6565126180648804\n",
      "epoch:  606  accuracy:  0.6148  loss:  0.6564931869506836\n",
      "epoch:  607  accuracy:  0.6149333333333333  loss:  0.6564765572547913\n",
      "epoch:  608  accuracy:  0.6143333333333333  loss:  0.6564598083496094\n",
      "epoch:  609  accuracy:  0.6151  loss:  0.6564416885375977\n",
      "epoch:  610  accuracy:  0.6145  loss:  0.6564241051673889\n",
      "epoch:  611  accuracy:  0.6152666666666666  loss:  0.6564064025878906\n",
      "epoch:  612  accuracy:  0.6147333333333334  loss:  0.6563882827758789\n",
      "epoch:  613  accuracy:  0.6156  loss:  0.6563693881034851\n",
      "epoch:  614  accuracy:  0.6147666666666667  loss:  0.6563456058502197\n",
      "epoch:  615  accuracy:  0.6156666666666667  loss:  0.6563173532485962\n",
      "epoch:  616  accuracy:  0.6147333333333334  loss:  0.6562880277633667\n",
      "epoch:  617  accuracy:  0.6152333333333333  loss:  0.6562587022781372\n",
      "epoch:  618  accuracy:  0.6148  loss:  0.6562312841415405\n",
      "epoch:  619  accuracy:  0.6146333333333334  loss:  0.6562080383300781\n",
      "epoch:  620  accuracy:  0.6151  loss:  0.6561881303787231\n",
      "epoch:  621  accuracy:  0.6146333333333334  loss:  0.6561706066131592\n",
      "epoch:  622  accuracy:  0.6152666666666666  loss:  0.6561528444290161\n",
      "epoch:  623  accuracy:  0.6147  loss:  0.6561342477798462\n",
      "epoch:  624  accuracy:  0.6156333333333334  loss:  0.6561142802238464\n",
      "epoch:  625  accuracy:  0.6146666666666667  loss:  0.6560941338539124\n",
      "epoch:  626  accuracy:  0.6154666666666667  loss:  0.6560732126235962\n",
      "epoch:  627  accuracy:  0.6146666666666667  loss:  0.6560506820678711\n",
      "epoch:  628  accuracy:  0.6156333333333334  loss:  0.6560298204421997\n",
      "epoch:  629  accuracy:  0.6147  loss:  0.6560086011886597\n",
      "epoch:  630  accuracy:  0.6159333333333333  loss:  0.6559877395629883\n",
      "epoch:  631  accuracy:  0.6149333333333333  loss:  0.6559658646583557\n",
      "epoch:  632  accuracy:  0.616  loss:  0.6559455990791321\n",
      "epoch:  633  accuracy:  0.6149666666666667  loss:  0.6559272408485413\n",
      "epoch:  634  accuracy:  0.6163  loss:  0.6559127569198608\n",
      "epoch:  635  accuracy:  0.6149333333333333  loss:  0.6558985114097595\n",
      "epoch:  636  accuracy:  0.6164666666666667  loss:  0.6558881998062134\n",
      "epoch:  637  accuracy:  0.6147333333333334  loss:  0.655881404876709\n",
      "epoch:  638  accuracy:  0.6166333333333334  loss:  0.6558743119239807\n",
      "epoch:  639  accuracy:  0.6152666666666666  loss:  0.6558620929718018\n",
      "epoch:  640  accuracy:  0.6167  loss:  0.6558360457420349\n",
      "epoch:  641  accuracy:  0.6148333333333333  loss:  0.6557990908622742\n",
      "epoch:  642  accuracy:  0.6164  loss:  0.6557523608207703\n",
      "epoch:  643  accuracy:  0.6155  loss:  0.6557096242904663\n",
      "epoch:  644  accuracy:  0.6157  loss:  0.6556839346885681\n",
      "epoch:  645  accuracy:  0.6162666666666666  loss:  0.6556733846664429\n",
      "epoch:  646  accuracy:  0.6149  loss:  0.6556717753410339\n",
      "epoch:  647  accuracy:  0.6165666666666667  loss:  0.6556718945503235\n",
      "epoch:  648  accuracy:  0.6148  loss:  0.6556604504585266\n",
      "epoch:  649  accuracy:  0.6169666666666667  loss:  0.6556400656700134\n",
      "epoch:  650  accuracy:  0.6147666666666667  loss:  0.6556026339530945\n",
      "epoch:  651  accuracy:  0.6167333333333334  loss:  0.6555653810501099\n",
      "epoch:  652  accuracy:  0.6155333333333334  loss:  0.655531644821167\n",
      "epoch:  653  accuracy:  0.6161666666666666  loss:  0.6555070281028748\n",
      "epoch:  654  accuracy:  0.6164  loss:  0.6554887890815735\n",
      "epoch:  655  accuracy:  0.6157  loss:  0.6554752588272095\n",
      "epoch:  656  accuracy:  0.6166  loss:  0.6554641723632812\n",
      "epoch:  657  accuracy:  0.6153333333333333  loss:  0.6554518342018127\n",
      "epoch:  658  accuracy:  0.6169  loss:  0.6554409861564636\n",
      "epoch:  659  accuracy:  0.6152  loss:  0.6554238200187683\n",
      "epoch:  660  accuracy:  0.617  loss:  0.655407190322876\n",
      "epoch:  661  accuracy:  0.6154333333333334  loss:  0.6553808450698853\n",
      "epoch:  662  accuracy:  0.6166333333333334  loss:  0.6553536653518677\n",
      "epoch:  663  accuracy:  0.6158  loss:  0.6553247570991516\n",
      "epoch:  664  accuracy:  0.6164333333333334  loss:  0.6552979350090027\n",
      "epoch:  665  accuracy:  0.6163333333333333  loss:  0.6552755236625671\n",
      "epoch:  666  accuracy:  0.6161666666666666  loss:  0.6552572846412659\n",
      "epoch:  667  accuracy:  0.6161666666666666  loss:  0.6552421450614929\n",
      "epoch:  668  accuracy:  0.6160666666666667  loss:  0.6552295088768005\n",
      "epoch:  669  accuracy:  0.617  loss:  0.6552186012268066\n",
      "epoch:  670  accuracy:  0.6154  loss:  0.6552079319953918\n",
      "epoch:  671  accuracy:  0.617  loss:  0.6551979184150696\n",
      "epoch:  672  accuracy:  0.6157333333333334  loss:  0.6551823019981384\n",
      "epoch:  673  accuracy:  0.6174  loss:  0.6551665663719177\n",
      "epoch:  674  accuracy:  0.6158666666666667  loss:  0.6551398634910583\n",
      "epoch:  675  accuracy:  0.6170333333333333  loss:  0.6551113724708557\n",
      "epoch:  676  accuracy:  0.6163666666666666  loss:  0.6550820469856262\n",
      "epoch:  677  accuracy:  0.6167  loss:  0.6550551652908325\n",
      "epoch:  678  accuracy:  0.6168  loss:  0.6550328135490417\n",
      "epoch:  679  accuracy:  0.6166666666666667  loss:  0.6550143361091614\n",
      "epoch:  680  accuracy:  0.6166666666666667  loss:  0.6550001502037048\n",
      "epoch:  681  accuracy:  0.6167  loss:  0.6549882292747498\n",
      "epoch:  682  accuracy:  0.617  loss:  0.6549789309501648\n",
      "epoch:  683  accuracy:  0.6161666666666666  loss:  0.6549686789512634\n",
      "epoch:  684  accuracy:  0.6178666666666667  loss:  0.6549569964408875\n",
      "epoch:  685  accuracy:  0.6164  loss:  0.6549439430236816\n",
      "epoch:  686  accuracy:  0.6180333333333333  loss:  0.6549274921417236\n",
      "epoch:  687  accuracy:  0.6161666666666666  loss:  0.6549085378646851\n",
      "epoch:  688  accuracy:  0.6181333333333333  loss:  0.6548873782157898\n",
      "epoch:  689  accuracy:  0.6166333333333334  loss:  0.6548622250556946\n",
      "epoch:  690  accuracy:  0.618  loss:  0.6548377871513367\n",
      "epoch:  691  accuracy:  0.6172333333333333  loss:  0.6548123955726624\n",
      "epoch:  692  accuracy:  0.6172333333333333  loss:  0.6547902822494507\n",
      "epoch:  693  accuracy:  0.6170333333333333  loss:  0.6547683477401733\n",
      "epoch:  694  accuracy:  0.617  loss:  0.6547476649284363\n",
      "epoch:  695  accuracy:  0.6171  loss:  0.6547279357910156\n",
      "epoch:  696  accuracy:  0.6169333333333333  loss:  0.6547091007232666\n",
      "epoch:  697  accuracy:  0.6170666666666667  loss:  0.6546903848648071\n",
      "epoch:  698  accuracy:  0.6169666666666667  loss:  0.6546728014945984\n",
      "epoch:  699  accuracy:  0.6171333333333333  loss:  0.6546552181243896\n",
      "epoch:  700  accuracy:  0.6172666666666666  loss:  0.6546375751495361\n",
      "epoch:  701  accuracy:  0.6170666666666667  loss:  0.654620885848999\n",
      "epoch:  702  accuracy:  0.6172  loss:  0.6546046137809753\n",
      "epoch:  703  accuracy:  0.6175  loss:  0.6545887589454651\n",
      "epoch:  704  accuracy:  0.6167333333333334  loss:  0.6545733213424683\n",
      "epoch:  705  accuracy:  0.6172666666666666  loss:  0.6545590162277222\n",
      "epoch:  706  accuracy:  0.6172666666666666  loss:  0.6545470356941223\n",
      "epoch:  707  accuracy:  0.6178333333333333  loss:  0.6545407772064209\n",
      "epoch:  708  accuracy:  0.6171  loss:  0.6545484066009521\n",
      "epoch:  709  accuracy:  0.6179  loss:  0.6545841693878174\n",
      "epoch:  710  accuracy:  0.6169666666666667  loss:  0.6546617746353149\n",
      "epoch:  711  accuracy:  0.6183333333333333  loss:  0.6547591090202332\n",
      "epoch:  712  accuracy:  0.6160333333333333  loss:  0.6547778844833374\n",
      "epoch:  713  accuracy:  0.618  loss:  0.6546626091003418\n",
      "epoch:  714  accuracy:  0.6174333333333333  loss:  0.6544625163078308\n",
      "epoch:  715  accuracy:  0.6174333333333333  loss:  0.6543967723846436\n",
      "epoch:  716  accuracy:  0.6180333333333333  loss:  0.6544899940490723\n",
      "epoch:  717  accuracy:  0.6170666666666667  loss:  0.6545454859733582\n",
      "epoch:  718  accuracy:  0.6181666666666666  loss:  0.6544528007507324\n",
      "epoch:  719  accuracy:  0.6176  loss:  0.6543353796005249\n",
      "epoch:  720  accuracy:  0.6175  loss:  0.6543434858322144\n",
      "epoch:  721  accuracy:  0.6182666666666666  loss:  0.6544060707092285\n",
      "epoch:  722  accuracy:  0.6170666666666667  loss:  0.6543746590614319\n",
      "epoch:  723  accuracy:  0.618  loss:  0.6542840003967285\n",
      "epoch:  724  accuracy:  0.6176666666666667  loss:  0.6542589068412781\n",
      "epoch:  725  accuracy:  0.6171666666666666  loss:  0.654295802116394\n",
      "epoch:  726  accuracy:  0.6181666666666666  loss:  0.6542940139770508\n",
      "epoch:  727  accuracy:  0.6179333333333333  loss:  0.6542293429374695\n",
      "epoch:  728  accuracy:  0.6178666666666667  loss:  0.6541904211044312\n",
      "epoch:  729  accuracy:  0.6182  loss:  0.6542019844055176\n",
      "epoch:  730  accuracy:  0.6177  loss:  0.6542091369628906\n",
      "epoch:  731  accuracy:  0.6184333333333333  loss:  0.6541734337806702\n",
      "epoch:  732  accuracy:  0.6179333333333333  loss:  0.6541323661804199\n",
      "epoch:  733  accuracy:  0.6177666666666667  loss:  0.654121994972229\n",
      "epoch:  734  accuracy:  0.6185  loss:  0.6541265249252319\n",
      "epoch:  735  accuracy:  0.6181333333333333  loss:  0.6541134119033813\n",
      "epoch:  736  accuracy:  0.6183  loss:  0.6540805697441101\n",
      "epoch:  737  accuracy:  0.6177  loss:  0.6540561318397522\n",
      "epoch:  738  accuracy:  0.6177333333333334  loss:  0.6540501117706299\n",
      "epoch:  739  accuracy:  0.6185333333333334  loss:  0.6540464162826538\n",
      "epoch:  740  accuracy:  0.6181666666666666  loss:  0.654030978679657\n",
      "epoch:  741  accuracy:  0.6183333333333333  loss:  0.6540060043334961\n",
      "epoch:  742  accuracy:  0.6178  loss:  0.6539843678474426\n",
      "epoch:  743  accuracy:  0.6178666666666667  loss:  0.6539703607559204\n",
      "epoch:  744  accuracy:  0.6185333333333334  loss:  0.653962254524231\n",
      "epoch:  745  accuracy:  0.6176666666666667  loss:  0.6539531350135803\n",
      "epoch:  746  accuracy:  0.6186  loss:  0.6539376378059387\n",
      "epoch:  747  accuracy:  0.6178333333333333  loss:  0.6539174914360046\n",
      "epoch:  748  accuracy:  0.6181  loss:  0.6538983583450317\n",
      "epoch:  749  accuracy:  0.6179333333333333  loss:  0.6538838744163513\n",
      "epoch:  750  accuracy:  0.6178666666666667  loss:  0.6538729667663574\n",
      "epoch:  751  accuracy:  0.6185  loss:  0.6538633108139038\n",
      "epoch:  752  accuracy:  0.6180666666666667  loss:  0.6538509130477905\n",
      "epoch:  753  accuracy:  0.6184  loss:  0.653834879398346\n",
      "epoch:  754  accuracy:  0.6178333333333333  loss:  0.6538166999816895\n",
      "epoch:  755  accuracy:  0.6182666666666666  loss:  0.6538002490997314\n",
      "epoch:  756  accuracy:  0.6183666666666666  loss:  0.6537859439849854\n",
      "epoch:  757  accuracy:  0.6178333333333333  loss:  0.6537733674049377\n",
      "epoch:  758  accuracy:  0.6183  loss:  0.6537612676620483\n",
      "epoch:  759  accuracy:  0.6177  loss:  0.6537479162216187\n",
      "epoch:  760  accuracy:  0.6184333333333333  loss:  0.6537338495254517\n",
      "epoch:  761  accuracy:  0.6180333333333333  loss:  0.6537193059921265\n",
      "epoch:  762  accuracy:  0.6182333333333333  loss:  0.6537047028541565\n",
      "epoch:  763  accuracy:  0.6181666666666666  loss:  0.6536902189254761\n",
      "epoch:  764  accuracy:  0.6181666666666666  loss:  0.6536765694618225\n",
      "epoch:  765  accuracy:  0.6181  loss:  0.6536636352539062\n",
      "epoch:  766  accuracy:  0.6181  loss:  0.6536514163017273\n",
      "epoch:  767  accuracy:  0.6186333333333334  loss:  0.6536393165588379\n",
      "epoch:  768  accuracy:  0.6181666666666666  loss:  0.6536272168159485\n",
      "epoch:  769  accuracy:  0.6184666666666667  loss:  0.6536153554916382\n",
      "epoch:  770  accuracy:  0.6182  loss:  0.6536023616790771\n",
      "epoch:  771  accuracy:  0.6183333333333333  loss:  0.6535899639129639\n",
      "epoch:  772  accuracy:  0.6182333333333333  loss:  0.6535754203796387\n",
      "epoch:  773  accuracy:  0.6183  loss:  0.6535612344741821\n",
      "epoch:  774  accuracy:  0.6182  loss:  0.6535478234291077\n",
      "epoch:  775  accuracy:  0.6182666666666666  loss:  0.6535341143608093\n",
      "epoch:  776  accuracy:  0.6182  loss:  0.6535212993621826\n",
      "epoch:  777  accuracy:  0.6181666666666666  loss:  0.6535078287124634\n",
      "epoch:  778  accuracy:  0.6183  loss:  0.6534935235977173\n",
      "epoch:  779  accuracy:  0.6184  loss:  0.6534801721572876\n",
      "epoch:  780  accuracy:  0.6183666666666666  loss:  0.6534668207168579\n",
      "epoch:  781  accuracy:  0.6184  loss:  0.6534538865089417\n",
      "epoch:  782  accuracy:  0.6181666666666666  loss:  0.6534410119056702\n",
      "epoch:  783  accuracy:  0.6186666666666667  loss:  0.6534291505813599\n",
      "epoch:  784  accuracy:  0.6185  loss:  0.6534183621406555\n",
      "epoch:  785  accuracy:  0.6188666666666667  loss:  0.6534106135368347\n",
      "epoch:  786  accuracy:  0.6184  loss:  0.6534019708633423\n",
      "epoch:  787  accuracy:  0.619  loss:  0.653398871421814\n",
      "epoch:  788  accuracy:  0.6179333333333333  loss:  0.6533902883529663\n",
      "epoch:  789  accuracy:  0.6194  loss:  0.6533868312835693\n",
      "epoch:  790  accuracy:  0.6181333333333333  loss:  0.6533733010292053\n",
      "epoch:  791  accuracy:  0.6192333333333333  loss:  0.6533622741699219\n",
      "epoch:  792  accuracy:  0.6181  loss:  0.6533377766609192\n",
      "epoch:  793  accuracy:  0.6191666666666666  loss:  0.6533125042915344\n",
      "epoch:  794  accuracy:  0.6186666666666667  loss:  0.6532845497131348\n",
      "epoch:  795  accuracy:  0.619  loss:  0.6532605290412903\n",
      "epoch:  796  accuracy:  0.619  loss:  0.653242826461792\n",
      "epoch:  797  accuracy:  0.6189  loss:  0.6532317399978638\n",
      "epoch:  798  accuracy:  0.6191666666666666  loss:  0.6532258987426758\n",
      "epoch:  799  accuracy:  0.6188333333333333  loss:  0.6532230377197266\n",
      "epoch:  800  accuracy:  0.6195666666666667  loss:  0.653223991394043\n",
      "epoch:  801  accuracy:  0.6182333333333333  loss:  0.6532241106033325\n",
      "epoch:  802  accuracy:  0.6195666666666667  loss:  0.6532251238822937\n",
      "epoch:  803  accuracy:  0.6182  loss:  0.6532155871391296\n",
      "epoch:  804  accuracy:  0.6196  loss:  0.6532004475593567\n",
      "epoch:  805  accuracy:  0.6184666666666667  loss:  0.6531683802604675\n",
      "epoch:  806  accuracy:  0.6197333333333334  loss:  0.6531359553337097\n",
      "epoch:  807  accuracy:  0.6193  loss:  0.6531049013137817\n",
      "epoch:  808  accuracy:  0.6194666666666667  loss:  0.6530815362930298\n",
      "epoch:  809  accuracy:  0.6196333333333334  loss:  0.6530648469924927\n",
      "epoch:  810  accuracy:  0.6193333333333333  loss:  0.6530523896217346\n",
      "epoch:  811  accuracy:  0.6197  loss:  0.6530435085296631\n",
      "epoch:  812  accuracy:  0.6196  loss:  0.6530390977859497\n",
      "epoch:  813  accuracy:  0.6196666666666667  loss:  0.6530379056930542\n",
      "epoch:  814  accuracy:  0.6191  loss:  0.6530388593673706\n",
      "epoch:  815  accuracy:  0.6198333333333333  loss:  0.6530435085296631\n",
      "epoch:  816  accuracy:  0.6187333333333334  loss:  0.6530378460884094\n",
      "epoch:  817  accuracy:  0.6199666666666667  loss:  0.6530307531356812\n",
      "epoch:  818  accuracy:  0.6190333333333333  loss:  0.6530014276504517\n",
      "epoch:  819  accuracy:  0.6201  loss:  0.652971088886261\n",
      "epoch:  820  accuracy:  0.6196  loss:  0.6529369354248047\n",
      "epoch:  821  accuracy:  0.6198  loss:  0.6529114842414856\n",
      "epoch:  822  accuracy:  0.6197333333333334  loss:  0.6528953313827515\n",
      "epoch:  823  accuracy:  0.6202  loss:  0.652887761592865\n",
      "epoch:  824  accuracy:  0.6200666666666667  loss:  0.6528862118721008\n",
      "epoch:  825  accuracy:  0.6195666666666667  loss:  0.6528893113136292\n",
      "epoch:  826  accuracy:  0.6202333333333333  loss:  0.652893602848053\n",
      "epoch:  827  accuracy:  0.6191666666666666  loss:  0.6528918147087097\n",
      "epoch:  828  accuracy:  0.6203  loss:  0.6528855562210083\n",
      "epoch:  829  accuracy:  0.6192666666666666  loss:  0.6528587937355042\n",
      "epoch:  830  accuracy:  0.6201333333333333  loss:  0.6528316736221313\n",
      "epoch:  831  accuracy:  0.6197333333333334  loss:  0.6527992486953735\n",
      "epoch:  832  accuracy:  0.6201333333333333  loss:  0.6527751088142395\n",
      "epoch:  833  accuracy:  0.6201666666666666  loss:  0.6527561545372009\n",
      "epoch:  834  accuracy:  0.6201333333333333  loss:  0.6527417898178101\n",
      "epoch:  835  accuracy:  0.62  loss:  0.6527296900749207\n",
      "epoch:  836  accuracy:  0.6202  loss:  0.652720034122467\n",
      "epoch:  837  accuracy:  0.6206  loss:  0.6527135372161865\n",
      "epoch:  838  accuracy:  0.6201333333333333  loss:  0.6527084708213806\n",
      "epoch:  839  accuracy:  0.6205333333333334  loss:  0.6527083516120911\n",
      "epoch:  840  accuracy:  0.6202  loss:  0.6527047157287598\n",
      "epoch:  841  accuracy:  0.6205333333333334  loss:  0.6527052521705627\n",
      "epoch:  842  accuracy:  0.62  loss:  0.6526960730552673\n",
      "epoch:  843  accuracy:  0.6205333333333334  loss:  0.6526886224746704\n",
      "epoch:  844  accuracy:  0.6201333333333333  loss:  0.652664840221405\n",
      "epoch:  845  accuracy:  0.6206666666666667  loss:  0.6526431441307068\n",
      "epoch:  846  accuracy:  0.6203  loss:  0.6526162028312683\n",
      "epoch:  847  accuracy:  0.6208333333333333  loss:  0.6525935530662537\n",
      "epoch:  848  accuracy:  0.6201  loss:  0.6525726914405823\n",
      "epoch:  849  accuracy:  0.6201333333333333  loss:  0.6525571942329407\n",
      "epoch:  850  accuracy:  0.6203666666666666  loss:  0.6525477766990662\n",
      "epoch:  851  accuracy:  0.6201666666666666  loss:  0.6525423526763916\n",
      "epoch:  852  accuracy:  0.6205333333333334  loss:  0.6525372266769409\n",
      "epoch:  853  accuracy:  0.6205666666666667  loss:  0.6525313854217529\n",
      "epoch:  854  accuracy:  0.6207  loss:  0.6525238156318665\n",
      "epoch:  855  accuracy:  0.6206  loss:  0.6525148153305054\n",
      "epoch:  856  accuracy:  0.6207666666666667  loss:  0.6525075435638428\n",
      "epoch:  857  accuracy:  0.6205333333333334  loss:  0.6524980664253235\n",
      "epoch:  858  accuracy:  0.6210666666666667  loss:  0.6524906158447266\n",
      "epoch:  859  accuracy:  0.6206333333333334  loss:  0.6524771451950073\n",
      "epoch:  860  accuracy:  0.6210333333333333  loss:  0.652465283870697\n",
      "epoch:  861  accuracy:  0.6203666666666666  loss:  0.6524460911750793\n",
      "epoch:  862  accuracy:  0.6206666666666667  loss:  0.6524268984794617\n",
      "epoch:  863  accuracy:  0.6207666666666667  loss:  0.6524052023887634\n",
      "epoch:  864  accuracy:  0.6208  loss:  0.6523850560188293\n",
      "epoch:  865  accuracy:  0.6205666666666667  loss:  0.6523674726486206\n",
      "epoch:  866  accuracy:  0.6208333333333333  loss:  0.6523528695106506\n",
      "epoch:  867  accuracy:  0.6207666666666667  loss:  0.6523411273956299\n",
      "epoch:  868  accuracy:  0.6206666666666667  loss:  0.6523315906524658\n",
      "epoch:  869  accuracy:  0.6209333333333333  loss:  0.6523255109786987\n",
      "epoch:  870  accuracy:  0.621  loss:  0.6523210406303406\n",
      "epoch:  871  accuracy:  0.6211333333333333  loss:  0.6523192524909973\n",
      "epoch:  872  accuracy:  0.6206333333333334  loss:  0.6523182988166809\n",
      "epoch:  873  accuracy:  0.6210333333333333  loss:  0.65232253074646\n",
      "epoch:  874  accuracy:  0.6208  loss:  0.6523259282112122\n",
      "epoch:  875  accuracy:  0.6213  loss:  0.6523309946060181\n",
      "epoch:  876  accuracy:  0.6204  loss:  0.6523218154907227\n",
      "epoch:  877  accuracy:  0.6212666666666666  loss:  0.6523058414459229\n",
      "epoch:  878  accuracy:  0.6207666666666667  loss:  0.652273952960968\n",
      "epoch:  879  accuracy:  0.6209333333333333  loss:  0.6522371172904968\n",
      "epoch:  880  accuracy:  0.6210333333333333  loss:  0.6522008180618286\n",
      "epoch:  881  accuracy:  0.6214333333333333  loss:  0.6521724462509155\n",
      "epoch:  882  accuracy:  0.6210666666666667  loss:  0.652154803276062\n",
      "epoch:  883  accuracy:  0.6210333333333333  loss:  0.6521453857421875\n",
      "epoch:  884  accuracy:  0.6215333333333334  loss:  0.6521413326263428\n",
      "epoch:  885  accuracy:  0.6209333333333333  loss:  0.6521421670913696\n",
      "epoch:  886  accuracy:  0.621  loss:  0.6521455645561218\n",
      "epoch:  887  accuracy:  0.6206666666666667  loss:  0.6521490812301636\n",
      "epoch:  888  accuracy:  0.6211  loss:  0.6521496176719666\n",
      "epoch:  889  accuracy:  0.6207666666666667  loss:  0.6521398425102234\n",
      "epoch:  890  accuracy:  0.6212  loss:  0.6521247625350952\n",
      "epoch:  891  accuracy:  0.6207  loss:  0.6520999670028687\n",
      "epoch:  892  accuracy:  0.6213333333333333  loss:  0.6520691514015198\n",
      "epoch:  893  accuracy:  0.6210333333333333  loss:  0.6520415544509888\n",
      "epoch:  894  accuracy:  0.6215333333333334  loss:  0.6520215272903442\n",
      "epoch:  895  accuracy:  0.6214  loss:  0.6520062685012817\n",
      "epoch:  896  accuracy:  0.6213  loss:  0.6519948244094849\n",
      "epoch:  897  accuracy:  0.6215  loss:  0.6519858241081238\n",
      "epoch:  898  accuracy:  0.6213666666666666  loss:  0.6519785523414612\n",
      "epoch:  899  accuracy:  0.6217333333333334  loss:  0.6519726514816284\n",
      "epoch:  900  accuracy:  0.6212  loss:  0.6519694328308105\n",
      "epoch:  901  accuracy:  0.6215666666666667  loss:  0.6519688963890076\n",
      "epoch:  902  accuracy:  0.6209666666666667  loss:  0.6519666314125061\n",
      "epoch:  903  accuracy:  0.6212666666666666  loss:  0.651967465877533\n",
      "epoch:  904  accuracy:  0.6207  loss:  0.6519601345062256\n",
      "epoch:  905  accuracy:  0.6214333333333333  loss:  0.6519510746002197\n",
      "epoch:  906  accuracy:  0.6208666666666667  loss:  0.6519328951835632\n",
      "epoch:  907  accuracy:  0.6214666666666666  loss:  0.6519126296043396\n",
      "epoch:  908  accuracy:  0.6209333333333333  loss:  0.6518876552581787\n",
      "epoch:  909  accuracy:  0.6219  loss:  0.6518648266792297\n",
      "epoch:  910  accuracy:  0.6216333333333334  loss:  0.6518442034721375\n",
      "epoch:  911  accuracy:  0.6218  loss:  0.6518293023109436\n",
      "epoch:  912  accuracy:  0.6215666666666667  loss:  0.6518198251724243\n",
      "epoch:  913  accuracy:  0.6214333333333333  loss:  0.6518137454986572\n",
      "epoch:  914  accuracy:  0.6219  loss:  0.6518083214759827\n",
      "epoch:  915  accuracy:  0.6210666666666667  loss:  0.6518025398254395\n",
      "epoch:  916  accuracy:  0.622  loss:  0.6517979502677917\n",
      "epoch:  917  accuracy:  0.6206666666666667  loss:  0.6517935991287231\n",
      "epoch:  918  accuracy:  0.6218666666666667  loss:  0.6517882347106934\n",
      "epoch:  919  accuracy:  0.6206666666666667  loss:  0.6517810225486755\n",
      "epoch:  920  accuracy:  0.6220333333333333  loss:  0.651773989200592\n",
      "epoch:  921  accuracy:  0.6207  loss:  0.6517623066902161\n",
      "epoch:  922  accuracy:  0.6219666666666667  loss:  0.6517492532730103\n",
      "epoch:  923  accuracy:  0.6208  loss:  0.6517334580421448\n",
      "epoch:  924  accuracy:  0.6219  loss:  0.6517179608345032\n",
      "epoch:  925  accuracy:  0.621  loss:  0.6517002582550049\n",
      "epoch:  926  accuracy:  0.6219  loss:  0.6516820788383484\n",
      "epoch:  927  accuracy:  0.6213  loss:  0.6516647338867188\n",
      "epoch:  928  accuracy:  0.6218  loss:  0.6516489386558533\n",
      "epoch:  929  accuracy:  0.6221666666666666  loss:  0.6516357064247131\n",
      "epoch:  930  accuracy:  0.6218333333333333  loss:  0.6516252756118774\n",
      "epoch:  931  accuracy:  0.6219333333333333  loss:  0.6516167521476746\n",
      "epoch:  932  accuracy:  0.6212666666666666  loss:  0.6516093611717224\n",
      "epoch:  933  accuracy:  0.6224  loss:  0.6516028046607971\n",
      "epoch:  934  accuracy:  0.6213666666666666  loss:  0.651599645614624\n",
      "epoch:  935  accuracy:  0.6220333333333333  loss:  0.6516007781028748\n",
      "epoch:  936  accuracy:  0.6212666666666666  loss:  0.651603639125824\n",
      "epoch:  937  accuracy:  0.6214333333333333  loss:  0.651613175868988\n",
      "epoch:  938  accuracy:  0.6217333333333334  loss:  0.651618242263794\n",
      "epoch:  939  accuracy:  0.6211333333333333  loss:  0.6516281962394714\n",
      "epoch:  940  accuracy:  0.6219666666666667  loss:  0.6516088843345642\n",
      "epoch:  941  accuracy:  0.6214666666666666  loss:  0.6515892148017883\n",
      "epoch:  942  accuracy:  0.6218666666666667  loss:  0.651542603969574\n",
      "epoch:  943  accuracy:  0.6219333333333333  loss:  0.6515005826950073\n",
      "epoch:  944  accuracy:  0.6211666666666666  loss:  0.651464581489563\n",
      "epoch:  945  accuracy:  0.6215  loss:  0.6514427065849304\n",
      "epoch:  946  accuracy:  0.6217333333333334  loss:  0.6514342427253723\n",
      "epoch:  947  accuracy:  0.6211333333333333  loss:  0.6514347791671753\n",
      "epoch:  948  accuracy:  0.6220666666666667  loss:  0.6514395475387573\n",
      "epoch:  949  accuracy:  0.6218666666666667  loss:  0.6514384150505066\n",
      "epoch:  950  accuracy:  0.6220666666666667  loss:  0.6514334678649902\n",
      "epoch:  951  accuracy:  0.6217666666666667  loss:  0.651415228843689\n",
      "epoch:  952  accuracy:  0.6222  loss:  0.6513943076133728\n",
      "epoch:  953  accuracy:  0.6213333333333333  loss:  0.6513663530349731\n",
      "epoch:  954  accuracy:  0.6217  loss:  0.6513442993164062\n",
      "epoch:  955  accuracy:  0.6217666666666667  loss:  0.6513285040855408\n",
      "epoch:  956  accuracy:  0.6216  loss:  0.6513174772262573\n",
      "epoch:  957  accuracy:  0.6217  loss:  0.6513100266456604\n",
      "epoch:  958  accuracy:  0.6217  loss:  0.6513044238090515\n",
      "epoch:  959  accuracy:  0.6220333333333333  loss:  0.6513009667396545\n",
      "epoch:  960  accuracy:  0.6213666666666666  loss:  0.651297390460968\n",
      "epoch:  961  accuracy:  0.6221666666666666  loss:  0.6512962579727173\n",
      "epoch:  962  accuracy:  0.622  loss:  0.6512935757637024\n",
      "epoch:  963  accuracy:  0.6216  loss:  0.651289701461792\n",
      "epoch:  964  accuracy:  0.6219333333333333  loss:  0.6512828469276428\n",
      "epoch:  965  accuracy:  0.6219666666666667  loss:  0.6512734293937683\n",
      "epoch:  966  accuracy:  0.6218333333333333  loss:  0.6512557864189148\n",
      "epoch:  967  accuracy:  0.6217  loss:  0.6512338519096375\n",
      "epoch:  968  accuracy:  0.6215  loss:  0.6512089967727661\n",
      "epoch:  969  accuracy:  0.6225333333333334  loss:  0.6511866450309753\n",
      "epoch:  970  accuracy:  0.622  loss:  0.6511667966842651\n",
      "epoch:  971  accuracy:  0.6219333333333333  loss:  0.6511501669883728\n",
      "epoch:  972  accuracy:  0.6220666666666667  loss:  0.6511361002922058\n",
      "epoch:  973  accuracy:  0.6219  loss:  0.6511236429214478\n",
      "epoch:  974  accuracy:  0.6216666666666667  loss:  0.6511126160621643\n",
      "epoch:  975  accuracy:  0.6218333333333333  loss:  0.6511020064353943\n",
      "epoch:  976  accuracy:  0.6219666666666667  loss:  0.6510918140411377\n",
      "epoch:  977  accuracy:  0.6220333333333333  loss:  0.6510820984840393\n",
      "epoch:  978  accuracy:  0.6221333333333333  loss:  0.6510735154151917\n",
      "epoch:  979  accuracy:  0.6222333333333333  loss:  0.6510657668113708\n",
      "epoch:  980  accuracy:  0.6224333333333333  loss:  0.6510610580444336\n",
      "epoch:  981  accuracy:  0.622  loss:  0.6510607004165649\n",
      "epoch:  982  accuracy:  0.6220666666666667  loss:  0.6510657668113708\n",
      "epoch:  983  accuracy:  0.6217  loss:  0.6510752439498901\n",
      "epoch:  984  accuracy:  0.6222  loss:  0.6510888338088989\n",
      "epoch:  985  accuracy:  0.6225333333333334  loss:  0.6510999202728271\n",
      "epoch:  986  accuracy:  0.6216333333333334  loss:  0.6511122584342957\n",
      "epoch:  987  accuracy:  0.6222333333333333  loss:  0.651106595993042\n",
      "epoch:  988  accuracy:  0.6215666666666667  loss:  0.651089072227478\n",
      "epoch:  989  accuracy:  0.6223666666666666  loss:  0.6510454416275024\n",
      "epoch:  990  accuracy:  0.6221666666666666  loss:  0.6509966254234314\n",
      "epoch:  991  accuracy:  0.6222666666666666  loss:  0.6509504914283752\n",
      "epoch:  992  accuracy:  0.6221333333333333  loss:  0.6509252190589905\n",
      "epoch:  993  accuracy:  0.6224333333333333  loss:  0.6509202122688293\n",
      "epoch:  994  accuracy:  0.6224666666666666  loss:  0.6509271264076233\n",
      "epoch:  995  accuracy:  0.6222  loss:  0.6509382724761963\n",
      "epoch:  996  accuracy:  0.6221  loss:  0.6509423851966858\n",
      "epoch:  997  accuracy:  0.6221333333333333  loss:  0.6509374976158142\n",
      "epoch:  998  accuracy:  0.6220333333333333  loss:  0.6509219408035278\n",
      "epoch:  999  accuracy:  0.6223333333333333  loss:  0.6508966088294983\n",
      "Shape of X_private: (5000, 58)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def read_data_from_csv(path):\n",
    "    \"\"\"Load datasets from CSV files.\n",
    "    Args:\n",
    "        path (str): Path to the CSV file.\n",
    "    Returns:\n",
    "        X (np.ndarray): Features of samples.\n",
    "        y (np.ndarray): Labels of samples, only provided in the public\n",
    "        datasets.\n",
    "    \"\"\"\n",
    "    assert os.path.exists(path), f'File not found: {path}!'\n",
    "    assert os.path.splitext(path)[-1] == '.csv', f'Unsupported file type {os.path.splitext(path)[-1]}!'\n",
    "    data = pd.read_csv(path)\n",
    "    column_list = data.columns.values.tolist()\n",
    "    if 'Label' in column_list:\n",
    "        # for the public dataset, label column is provided.\n",
    "        column_list.remove('Label')\n",
    "        X = data[column_list].values\n",
    "        y = data['Label'].astype('int').values\n",
    "        return X, y\n",
    "    else:\n",
    "        # for the private dataset, label column is not provided.\n",
    "        X = data[column_list].values\n",
    "        return X\n",
    "\n",
    "\n",
    "X_public, y_public = read_data_from_csv('assignment_5_public.csv')\n",
    "print('Shape of X_public:', X_public.shape)  # n_sample, m_feature (30000, 58)\n",
    "print('Shape of y_public:', y_public.shape)  # n_sample (30000,)\n",
    "'''\n",
    "CODE HERE!\n",
    "'''\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(58, 64).cuda()\n",
    "        # self.fc2 = nn.Linear(128, 64).cuda()\n",
    "        self.fc3 = nn.Linear(64, 32).cuda()\n",
    "        self.fc4 = nn.Linear(32, 1).cuda()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        # x = self.fc2(x)\n",
    "        # x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_model(X, y, model, criterion, optimizer, num_epochs):\n",
    "    X = torch.tensor(X, dtype=torch.float32).cuda()\n",
    "    X = (X - torch.min(X)) / (torch.max(X) - torch.min(X))\n",
    "    y = torch.tensor(y, dtype=torch.float32).cuda().reshape(-1, 1)\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        outputs = (outputs >= 0.5).float()\n",
    "        accuracy = accuracy_score(y.cpu().numpy(), outputs.cpu().numpy())\n",
    "        print(\"epoch: \", epoch, \" accuracy: \", accuracy, \" loss: \", loss.item())\n",
    "\n",
    "\n",
    "model = NeuralNetwork()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_model(X_public, y_public, model, criterion, optimizer, num_epochs=1000)\n",
    "\n",
    "\n",
    "X_private = read_data_from_csv('assignment_5_private.csv')\n",
    "print('Shape of X_private:', X_private.shape) # k_sample, m_feature (5000, 58)\n",
    "\n",
    "import numpy as np\n",
    "# remove and make your own predictions.\n",
    "# preds = np.full(len(X_private), -1, dtype=int)\n",
    "\n",
    "'''\n",
    "CODE HERE!\n",
    "e.g.,\n",
    "preds = np.full(len(X_private), -1, dtype=int)\n",
    "'''\n",
    "\n",
    "X_private = torch.tensor(X_private, dtype=torch.float32).cuda()\n",
    "preds = model(X_private)\n",
    "preds = (preds >= 0.5).float()\n",
    "preds = preds.cpu().numpy().reshape(-1)\n",
    "\n",
    "submission = pd.DataFrame({'Label': preds})\n",
    "submission.to_csv('assignment_5.csv', index=True, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622da552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
